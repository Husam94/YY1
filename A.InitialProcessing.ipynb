{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f124bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#-------------------\n",
    "import poseigen_seaside.basics as se\n",
    "import poseigen_seaside.metrics as mex\n",
    "import poseigen_chisel as chis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a411b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafolder = se.NewFolder('data_1')\n",
    "os.chdir(os.getcwd() + datafolder )\n",
    "#------------------------\n",
    "tomain = './../'\n",
    "hg38folder = tomain + 'hg38/'\n",
    "#-------------------------\n",
    "# we have a dataset_identifier file already here. \n",
    "data_source = pd.read_excel('Dataset_Identifiers.xlsx')\n",
    "#-------------------------\n",
    "bamfolder = se.NewFolder('bam')\n",
    "peaksfolder = se.NewFolder('peaks')\n",
    "#-------------------------\n",
    "curfolder = se.NewFolder('currents')\n",
    "procfolder = se.NewFolder(curfolder + 'processed')\n",
    "fullfolder = se.NewFolder(curfolder + 'full') \n",
    "lowerfolder = se.NewFolder(curfolder + 'lowres') \n",
    "autosfolder = se.NewFolder(curfolder + 'autos')\n",
    "winfolder = se.NewFolder(curfolder + 'win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Downloading all files\n",
    "# path_A = 'https://www.encodeproject.org/files/'\n",
    "# path_B = '/@@download/'\n",
    "# path_C = '.bam'\n",
    "\n",
    "# for index, row in data_source.iterrows():\n",
    "#     newp = bamfolder + row['newid'] + path_C\n",
    "#     if os.path.exists(newp) is False: \n",
    "#         se.download_url(path_A + row['id'] + path_B + row['id'] + path_C, newp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowestres = 10\n",
    "CTreso = 50\n",
    "window = 200 #average size of fragments abouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e017d7",
   "metadata": {},
   "source": [
    "# YY1 Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !macs3 callpeak -t `ls ./bam/YY1*.bam` -c `ls ./bam/Input_BGG*.bam` -f BAM -g hs -q 0.001 -n YY1 --outdir ./peaks/YY1 --call-summits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb913d2",
   "metadata": {},
   "source": [
    "# YY1 and Histone Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3460d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['YY1' 'Input_BGG']\n",
      " ['H3K4me3' 'Input_AKY']\n",
      " ['H3K27ac' 'Input_AKY']\n",
      " ['H3K27me3' 'Input_AKY']\n",
      " ['H3K4me1' 'Input_AKY']\n",
      " ['H3K36me3' 'Input_AKY']\n",
      " ['H3K9me3' 'Input_AKY']\n",
      " ['H3K9ac' 'Input_AKY']\n",
      " ['H3K4me2' 'Input_AKY']\n",
      " ['H4K20me1' 'Input_AKY']\n",
      " ['H2AFZ' 'Input_AKY']\n",
      " ['H3K79me2' 'Input_AKY']]\n",
      "['H2AFZ' 'H3K27ac' 'H3K27me3' 'H3K36me3' 'H3K4me1' 'H3K4me2' 'H3K4me3'\n",
      " 'H3K79me2' 'H3K9ac' 'H3K9me3' 'H4K20me1' 'Input_AKY' 'Input_BGG' 'YY1']\n"
     ]
    }
   ],
   "source": [
    "# I want pairs of its target and its input. \n",
    "\n",
    "subjects = ['yy1', 'histone']\n",
    "\n",
    "pairs = np.concatenate([data_source[data_source['target_type'] == tar][['target', 'control']].drop_duplicates().to_numpy()\n",
    "         for tar in subjects])\n",
    "\n",
    "targets = np.unique(pairs)\n",
    "\n",
    "print(pairs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a69a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictd stuff\n",
    "\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/YY1_Rep1.bam` -g hs --outdir ./peaks/YY1/predictd/Rep1\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/YY1_Rep2.bam` -g hs --outdir ./peaks/YY1/predictd/Rep2\n",
    "\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep1.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep1\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep2.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep2\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep3.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep3\n",
    "\n",
    "# !for r in Rep1 Rep2; do for h in H3K4me3 H3K27ac H3K27me3 H3K4me1 H3K36me3 H3K9me3 H3K9ac H3K4me2 H4K20me1 H2AFZ H3K79me2; do macs3 predictd -i `ls ./../../data/!ENCODE/bam/\"$h\"_\"$r\"*.bam` -g hs --outdir ./peaks/$h/$r/predictd; done; done\n",
    "# !for r in Rep1 Rep2 Rep3; do for h in Input_AKY Input_BGG; do macs3 predictd -i `ls ./../../data/!ENCODE/bam/\"$h\"_\"$r\"*.bam` -g hs --outdir ./peaks/$h/$r/predictd; done; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23c19597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in data_source[data_source['target'].isin(targets)].iterrows(): \n",
    "#     target, rep, newid, read, predd = row['target'], row['rep'], row['newid'], row['read'], row['predictd']\n",
    "\n",
    "#     paio, readl = (True, None) if read == 'Paired' else (False, int(predd))\n",
    "#     print(readl)\n",
    "\n",
    "#     fpath = fullfolder + target + '_' + str(rep) + '_' + 'full'\n",
    "#     lrpath = lowerfolder + target + '_' + str(rep) + '_' + 'lowres'\n",
    "#     autopath = autosfolder + target + '_' + str(rep) + '_' + 'autos'\n",
    "\n",
    "#     if os.path.exists(fpath + '.p') is False: \n",
    "\n",
    "#         full = chis.Bam2Current(bamfolder + newid + '.bam', hg38_sizes, hg38_id, select_BS_ids = hg38_basic_id, \n",
    "#                         newreso = lowestres, resomode = np.mean, stranded = False, \n",
    "#                         read_length = readl, paired = paio, \n",
    "#                         make_index = True, dtype = np.float32)\n",
    "    \n",
    "#         se.PickleDump(full, fpath)\n",
    "    \n",
    "#     if os.path.exists(lrpath + '.p') is False: \n",
    "\n",
    "#         full = se.PickleLoad(fpath)\n",
    "\n",
    "#         lower = chis.LowerResCurrent(full, lowestres, CTreso, resomode = np.mean, dtype = np.float32)\n",
    "\n",
    "#         se.PickleDump(lower, lrpath)\n",
    "    \n",
    "#     if os.path.exists(autopath + '.p') is False: \n",
    "\n",
    "#         lower = se.PickleLoad(lrpath)\n",
    "\n",
    "#         autoz = chis.CurrentSelect(lower, hg38_basic_id, hg38_auto_ids)\n",
    "\n",
    "#         se.PickleDump(autoz, autopath)\n",
    "\n",
    "#     print(f'finished {target}, {rep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6efc74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each file we smooth by mean, then we remove blacklist regions, then we scale to total score. \n",
    "\n",
    "# hg38_basic_BLC_LR50 = se.PickleLoad(hg38folder + 'hg38_basic_BLC_LR50') #0s are bad\n",
    "\n",
    "# for index, row in data_source[data_source['target'].isin(targets)].iterrows(): \n",
    "#     target, rep, newid, read, predd = row['target'], row['rep'], row['newid'], row['read'], row['predictd']\n",
    "\n",
    "#     autopath = autosfolder + target + '_' + str(rep) + '_' + 'autos'\n",
    "\n",
    "#     winpath = winfolder + target + '_' + str(rep) + '_' + 'win'\n",
    "\n",
    "#     if os.path.exists(winpath + '.p') is False:\n",
    "\n",
    "#         autos = se.PickleLoad(autopath)\n",
    "        \n",
    "#         win = chis.CurrentWindower(autos, reso = CTreso, mode = np.mean, window = window, \n",
    "#                                 center = 0, extend = 0, dtype = np.float32, indiv = True)\n",
    "        \n",
    "#         win2 = chis.CurrentModifier(win, hg38_basic_BLC_LR50,\n",
    "#                                 mode = np.multiply, dtype = np.float32, single = False)\n",
    "        \n",
    "#         se.PickleDump(win2, winpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f897039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in targets: \n",
    "#     reps = [1,2,3] if 'Input' in t else [1,2]\n",
    "\n",
    "#     print(t)\n",
    "\n",
    "    # targ_vals = chis.Currents2Current([se.PickleLoad(winfolder + t + '_' + str(rep) + '_' + 'win')\n",
    "    #                                 for rep in reps]) ####################\n",
    "    \n",
    "    # targ_vals_scaled = chis.CurrentScaler(targ_vals, rounds = 1, dtype = np.float64)\n",
    "\n",
    "    # targ_vals_mean = chis.CurrentMerger(targ_vals, mode = np.mean, dtype = np.float32)\n",
    "\n",
    "    # for d, s in zip([targ_vals_scaled, targ_vals_mean], \n",
    "    #                 [t + '_scaled', t + '_mean']):\n",
    "        \n",
    "    #     se.PickleDump(d, procfolder + s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9112253e",
   "metadata": {},
   "source": [
    "## Over Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for papa in pairs: \n",
    "\n",
    "    targ_mean, inp_mean = [se.PickleLoad(procfolder + didi + '_mean') for didi in papa]\n",
    "\n",
    "    targ_overinp_mode = [mex.BetaPrime_Mode(x, y) for x,y in zip(targ_mean, inp_mean)]\n",
    "\n",
    "    targ_overinp_exp = [np.hstack([x,y]) for x,y in zip(targ_mean, inp_mean)]\n",
    "\n",
    "    [se.PickleDump(x, procfolder + papa[0] + '_' + y) for x,y in zip([targ_overinp_mode, targ_overinp_exp], \n",
    "                                                                     ['mode', 'exp'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f26b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_mean_vals = np.vstack(inp_mean).reshape(-1)\n",
    "\n",
    "inp_mean_vals_filt = inp_mean_vals[(inp_mean_vals > 0) * (inp_mean_vals < 10)]\n",
    "\n",
    "#plt.hist(inp_mean_vals_filt, bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b522f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['H3K4me3', 'H3K27ac', 'H3K27me3', 'H3K4me1', 'H3K36me3', 'H3K9me3',\n",
       "       'H3K9ac', 'H3K4me2', 'H4K20me1', 'H2AFZ', 'H3K79me2'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histones = data_source[data_source['target_type'] == 'histone']['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_mode = chis.Currents2Current([se.PickleLoad(procfolder + h + '_mode') for h in histones])\n",
    "\n",
    "se.PickleDump(his_mode, procfolder + 'his_mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "his_inp_means = chis.Currents2Current([se.PickleLoad(procfolder + h + '_mode') for h in histones])\n",
    "\n",
    "se.PickleDump(his_mode, procfolder + 'his_mode')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
