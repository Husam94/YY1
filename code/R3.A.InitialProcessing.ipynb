{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f124bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import poseigen_seaside.basics as se\n",
    "import poseigen_chisel as chis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomain = '../../../../'\n",
    "essentialsfolder = tomain + 'Essentials/'\n",
    "hg38folder = essentialsfolder + 'hg38/'\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "hg38_id, hg38_sizes = se.PickleLoad(hg38folder + 'hg38_id_sizes')\n",
    "\n",
    "hg38_basic_id, hg38_basic_sizes = se.PickleLoad(hg38folder + 'hg38_basic_id_sizes')\n",
    "\n",
    "hg38_auto_ids = hg38_basic_id[:-3]\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "lowestres = 10\n",
    "CTreso = 50\n",
    "\n",
    "window = 200 #average size of fragments abouts\n",
    "\n",
    "#----------------------------------\n",
    "\n",
    "encodefolder = se.NewFolder(tomain + 'data/' + '!ENCODE')\n",
    "\n",
    "data_source = pd.read_excel(encodefolder + 'Dataset_Identifiers.xlsx')\n",
    "\n",
    "bamfolder = encodefolder + 'bam/'\n",
    "curentsfolder = encodefolder + 'currents/'\n",
    "fullfolder = curentsfolder + 'full/'\n",
    "lowerfolder = curentsfolder + 'lowres/'\n",
    "autosfolder = curentsfolder + 'autos/'\n",
    "winfolder = curentsfolder + 'win/'\n",
    "\n",
    "procfolder = se.NewFolder(curentsfolder + 'processed')\n",
    "\n",
    "#----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e017d7",
   "metadata": {},
   "source": [
    "# YY1 Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016c6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !macs3 callpeak -t `ls ./../../data/!ENCODE/bam/YY1*.bam` -c `ls ./../../data/!ENCODE/bam/Input_BGG*.bam` -f BAM -g hs -q 0.001 -n YY1 --outdir ./peaks/YY1 --call-summits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb913d2",
   "metadata": {},
   "source": [
    "# YY1 and Histone Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3460d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['YY1' 'Input_BGG']\n",
      " ['H3K4me3' 'Input_AKY']\n",
      " ['H3K27ac' 'Input_AKY']\n",
      " ['H3K27me3' 'Input_AKY']\n",
      " ['H3K4me1' 'Input_AKY']\n",
      " ['H3K36me3' 'Input_AKY']\n",
      " ['H3K9me3' 'Input_AKY']\n",
      " ['H3K9ac' 'Input_AKY']\n",
      " ['H3K4me2' 'Input_AKY']\n",
      " ['H4K20me1' 'Input_AKY']\n",
      " ['H2AFZ' 'Input_AKY']\n",
      " ['H3K79me2' 'Input_AKY']]\n",
      "['H2AFZ' 'H3K27ac' 'H3K27me3' 'H3K36me3' 'H3K4me1' 'H3K4me2' 'H3K4me3'\n",
      " 'H3K79me2' 'H3K9ac' 'H3K9me3' 'H4K20me1' 'Input_AKY' 'Input_BGG' 'YY1']\n"
     ]
    }
   ],
   "source": [
    "# I want pairs of its target and its input. \n",
    "\n",
    "subjects = ['yy1', 'histone']\n",
    "\n",
    "pairs = np.concatenate([data_source[data_source['target_type'] == tar][['target', 'control']].drop_duplicates().to_numpy()\n",
    "         for tar in subjects])\n",
    "\n",
    "targets = np.unique(pairs)\n",
    "\n",
    "print(pairs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a69a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictd stuff\n",
    "\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/YY1_Rep1.bam` -g hs --outdir ./peaks/YY1/predictd/Rep1\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/YY1_Rep2.bam` -g hs --outdir ./peaks/YY1/predictd/Rep2\n",
    "\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep1.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep1\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep2.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep2\n",
    "# !macs3 predictd -i `ls ./../../data/!ENCODE/bam/Input_BGG_Rep3.bam` -g hs --outdir ./peaks/Input_BGG/predictd/Rep3\n",
    "\n",
    "# !for r in Rep1 Rep2; do for h in H3K4me3 H3K27ac H3K27me3 H3K4me1 H3K36me3 H3K9me3 H3K9ac H3K4me2 H4K20me1 H2AFZ H3K79me2; do macs3 predictd -i `ls ./../../data/!ENCODE/bam/\"$h\"_\"$r\"*.bam` -g hs --outdir ./peaks/$h/$r/predictd; done; done\n",
    "# !for r in Rep1 Rep2 Rep3; do for h in Input_AKY Input_BGG; do macs3 predictd -i `ls ./../../data/!ENCODE/bam/\"$h\"_\"$r\"*.bam` -g hs --outdir ./peaks/$h/$r/predictd; done; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c19597",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data_source[data_source['target'].isin(targets)].iterrows(): \n",
    "    target, rep, newid, read, predd = row['target'], row['rep'], row['newid'], row['read'], row['predictd']\n",
    "\n",
    "    paio, readl = (True, None) if read == 'Paired' else (False, int(predd))\n",
    "    print(readl)\n",
    "\n",
    "    fpath = fullfolder + target + '_' + str(rep) + '_' + 'full'\n",
    "    lrpath = lowerfolder + target + '_' + str(rep) + '_' + 'lowres'\n",
    "    autopath = autosfolder + target + '_' + str(rep) + '_' + 'autos'\n",
    "\n",
    "    if os.path.exists(fpath + '.p') is False: \n",
    "\n",
    "        full = chis.Bam2Current(bamfolder + newid + '.bam', hg38_sizes, hg38_id, select_BS_ids = hg38_basic_id, \n",
    "                        newreso = lowestres, resomode = np.mean, stranded = False, \n",
    "                        read_length = readl, paired = paio, \n",
    "                        make_index = True, dtype = np.float32)\n",
    "    \n",
    "        se.PickleDump(full, fpath)\n",
    "    \n",
    "    if os.path.exists(lrpath + '.p') is False: \n",
    "\n",
    "        full = se.PickleLoad(fpath)\n",
    "\n",
    "        lower = chis.LowerResCurrent(full, lowestres, CTreso, resomode = np.mean, dtype = np.float32)\n",
    "\n",
    "        se.PickleDump(lower, lrpath)\n",
    "    \n",
    "    if os.path.exists(autopath + '.p') is False: \n",
    "\n",
    "        lower = se.PickleLoad(lrpath)\n",
    "\n",
    "        autoz = chis.CurrentSelect(lower, hg38_basic_id, hg38_auto_ids)\n",
    "\n",
    "        se.PickleDump(autoz, autopath)\n",
    "\n",
    "    print(f'finished {target}, {rep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file we smooth by mean, then we remove blacklist regions, then we scale to total score. \n",
    "\n",
    "hg38_basic_BLC_LR50 = se.PickleLoad(hg38folder + 'hg38_basic_BLC_LR50') #0s are bad\n",
    "\n",
    "for index, row in data_source[data_source['target'].isin(targets)].iterrows(): \n",
    "    target, rep, newid, read, predd = row['target'], row['rep'], row['newid'], row['read'], row['predictd']\n",
    "\n",
    "    autopath = autosfolder + target + '_' + str(rep) + '_' + 'autos'\n",
    "\n",
    "    winpath = winfolder + target + '_' + str(rep) + '_' + 'win'\n",
    "\n",
    "    if os.path.exists(winpath + '.p') is False:\n",
    "\n",
    "        autos = se.PickleLoad(autopath)\n",
    "        \n",
    "        win = chis.CurrentWindower(autos, reso = CTreso, mode = np.mean, window = window, \n",
    "                                center = 0, extend = 0, dtype = np.float32, indiv = True)\n",
    "        \n",
    "        win2 = chis.CurrentModifier(win, hg38_basic_BLC_LR50,\n",
    "                                mode = np.multiply, dtype = np.float32, single = False)\n",
    "        \n",
    "        se.PickleDump(win2, winpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f897039",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in targets: \n",
    "    reps = [1,2,3] if 'Input' in t else [1,2]\n",
    "\n",
    "    print(t)\n",
    "\n",
    "    targ_vals = chis.Currents2Current([se.PickleLoad(winfolder + t + '_' + str(rep) + '_' + 'win')\n",
    "                                    for rep in reps]) ####################\n",
    "    \n",
    "    targ_vals_scaled = chis.CurrentScaler(targ_vals, rounds = 1, dtype = np.float64)\n",
    "\n",
    "    targ_vals_mean = chis.CurrentMerger(targ_vals, mode = np.mean, dtype = np.float32)\n",
    "\n",
    "    for d, s in zip([targ_vals_scaled, targ_vals_mean], \n",
    "                    [t + '_scaled', t + '_mean']):\n",
    "        \n",
    "        se.PickleDump(d, procfolder + s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
